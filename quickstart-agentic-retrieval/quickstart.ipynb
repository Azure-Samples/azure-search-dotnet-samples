{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8332ffe",
   "metadata": {},
   "source": [
    "# Quickstart: Agentic retrieval in Azure AI Search\n",
    "\n",
    "Use this notebook to get started with [agentic retrieval](https://learn.microsoft.com/azure/search/search-agentic-retrieval-concept) in Azure AI Search, which integrates an Azure OpenAI chat completion model to process queries, retrieve relevant content from indexed documents, and generate natural-language answers.\n",
    "\n",
    "Steps in this notebook include:\n",
    "\n",
    "1. Creating and loading an `earth-at-night` search index.\n",
    "\n",
    "1. Creating an `earth-knowledge-source` that targets your index.\n",
    "\n",
    "1. Creating an `earth-knowledge-agent` that targets your knowledge source and an LLM for query planning and answer synthesis.\n",
    "\n",
    "1. Using the agent to fetch, rank, and synthesize relevant information from the index.\n",
    "\n",
    "This notebook provides a high-level demonstration of agentic retrieval. For more detailed guidance, see [Quickstart: Run agentic retrieval in Azure AI Search](https://learn.microsoft.com/azure/search/search-get-started-agentic-retrieval?pivots=programming-language-csharp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03f1a5e",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "+ An [Azure AI Search service](https://learn.microsoft.com/azure/search/search-create-service-portal) on the Basic tier or higher with [semantic ranker enabled](https://learn.microsoft.com/azure/search/semantic-how-to-enable-disable).\n",
    "\n",
    "+ An [Azure AI Foundry project](https://learn.microsoft.com/azure/ai-foundry/how-to/create-projects) and Azure AI Foundry resource. When you create a project, the resource is automatically created.\n",
    "\n",
    "+ A [supported chat completion model](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-create#supported-models). This sample uses `gpt-5`.\n",
    "\n",
    "+ A text embedding model. This sample uses `text-embedding-3-large`.\n",
    "\n",
    "+ [Visual Studio Code](https://code.visualstudio.com/download)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db21c7",
   "metadata": {},
   "source": [
    "## Configure access\n",
    "\n",
    "This notebook assumes that you're using Microsoft Entra ID for authentication and role assignments for authorization.\n",
    "\n",
    "To configure role-based access:\n",
    "\n",
    "1. Sign in to the [Azure portal](https://portal.azure.com).\n",
    "\n",
    "1. On your Azure AI Search service:\n",
    "\n",
    "   1. [Enable role-based access](https://learn.microsoft.com/azure/search/search-security-enable-roles).\n",
    "\n",
    "   1. [Create a system-assigned managed identity](https://learn.microsoft.com/azure/search/search-howto-managed-identities-data-sources#create-a-system-managed-identity) on your Azure AI Search service.\n",
    "\n",
    "   1. [Assign the following roles](https://learn.microsoft.com/azure/search/search-security-rbac#how-to-assign-roles-in-the-azure-portal) to yourself.\n",
    "\n",
    "      + **Search Service Contributor**\n",
    "\n",
    "      + **Search Index Data Contributor**\n",
    "\n",
    "      + **Search Index Data Reader**\n",
    "\n",
    "1. On your Azure AI Foundry resource, assign **Cognitive Services User** to the managed identity of your search service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ece34",
   "metadata": {},
   "source": [
    "## Set up connections\n",
    "\n",
    "The `sample.env` file contains environment variables for connections to Azure AI Search and Azure OpenAI in Azure AI Foundry. Agentic retrieval requires these connections for document retrieval, query planning, and query execution.\n",
    "\n",
    "To set up the connections:\n",
    "\n",
    "1. Sign in to the [Azure portal](https://portal.azure.com).\n",
    "\n",
    "2. Get the endpoints for Azure AI Search (`https://your-search-service.search.windows.net`) and Azure OpenAI in Azure AI Foundry (`https://your-foundry-resource.openai.azure.com`).\n",
    "\n",
    "3. Save the `sample.env` file as `.env` on your local system.\n",
    "\n",
    "4. Update the `.env` file with the retrieved endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e3ddfe",
   "metadata": {},
   "source": [
    "## Install packages and load connections\n",
    "\n",
    "This step installs the packages for this notebook and establishes connections to Azure AI Search and Azure OpenAI in Azure AI Foundry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b8a3b0",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.Identity, 1.15.0</span></li><li><span>Azure.Search.Documents, 11.7.0-beta.7</span></li><li><span>dotenv.net, 4.0.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Azure.Search.Documents, 11.7.0-beta.7\"\n",
    "#r \"nuget: Azure.Identity, 1.15.0\"\n",
    "#r \"nuget:dotenv.net, 4.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc4a83d4",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using dotenv.net;\n",
    "using Azure.Identity;\n",
    "\n",
    "// .env should be in the same directory as this notebook\n",
    "DotEnv.Load(options: new DotEnvOptions(envFilePaths: new[] { \".env\" }, ignoreExceptions: false));\n",
    "\n",
    "// Get environment variables with defaults where appropriate\n",
    "string searchEndpoint = Environment.GetEnvironmentVariable(\"SEARCH_ENDPOINT\")\n",
    "    ?? throw new InvalidOperationException(\"SEARCH_ENDPOINT isn't set.\");\n",
    "string aoaiEndpoint = Environment.GetEnvironmentVariable(\"AOAI_ENDPOINT\")\n",
    "    ?? throw new InvalidOperationException(\"AOAI_ENDPOINT isn't set.\");\n",
    "\n",
    "string aoaiEmbeddingModel = \"text-embedding-3-large\";\n",
    "string aoaiEmbeddingDeployment = \"text-embedding-3-large\";\n",
    "string aoaiGptModel = \"gpt-5\";\n",
    "string aoaiGptDeployment = \"gpt-5\";\n",
    "\n",
    "string indexName = \"earth-at-night\";\n",
    "string knowledgeSourceName = \"earth-knowledge-source\";\n",
    "string knowledgeAgentName = \"earth-knowledge-agent\";\n",
    "\n",
    "var credential = new DefaultAzureCredential();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d85e5a",
   "metadata": {},
   "source": [
    "## Create an index in Azure AI Search\n",
    "\n",
    "This step creates a search index that contains plain text and vector content. You can use an existing index, but it must meet the criteria for [agentic retrieval workloads](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-index). The primary schema requirement is a semantic configuration with a `DefaultConfigurationName`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23942582",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth-at-night' created or updated successfully.\r\n"
     ]
    }
   ],
   "source": [
    "using Azure.Search.Documents.Indexes;\n",
    "using Azure.Search.Documents.Indexes.Models;\n",
    "\n",
    "// Define fields for the index\n",
    "var fields = new List<SearchField>\n",
    "{\n",
    "    new SimpleField(\"id\", SearchFieldDataType.String) { IsKey = true, IsFilterable = true, IsSortable = true, IsFacetable = true },\n",
    "    new SearchField(\"page_chunk\", SearchFieldDataType.String) { IsFilterable = false, IsSortable = false, IsFacetable = false },\n",
    "    new SearchField(\"page_embedding_text_3_large\", SearchFieldDataType.Collection(SearchFieldDataType.Single)) { VectorSearchDimensions = 3072, VectorSearchProfileName = \"hnsw_text_3_large\" },\n",
    "    new SimpleField(\"page_number\", SearchFieldDataType.Int32) { IsFilterable = true, IsSortable = true, IsFacetable = true }\n",
    "};\n",
    "\n",
    "// Define a vectorizer\n",
    "var vectorizer = new AzureOpenAIVectorizer(vectorizerName: \"azure_openai_text_3_large\")\n",
    "{\n",
    "    Parameters = new AzureOpenAIVectorizerParameters\n",
    "    {\n",
    "        ResourceUri = new Uri(aoaiEndpoint),\n",
    "        DeploymentName = aoaiEmbeddingDeployment,\n",
    "        ModelName = aoaiEmbeddingModel\n",
    "    }\n",
    "};\n",
    "\n",
    "// Define a vector search profile and algorithm\n",
    "var vectorSearch = new VectorSearch()\n",
    "{\n",
    "    Profiles =\n",
    "    {\n",
    "        new VectorSearchProfile(\n",
    "            name: \"hnsw_text_3_large\",\n",
    "            algorithmConfigurationName: \"alg\"\n",
    "        )\n",
    "        {\n",
    "            VectorizerName = \"azure_openai_text_3_large\"\n",
    "        }\n",
    "    },\n",
    "    Algorithms =\n",
    "    {\n",
    "        new HnswAlgorithmConfiguration(name: \"alg\")\n",
    "    },\n",
    "    Vectorizers =\n",
    "    {\n",
    "        vectorizer\n",
    "    }\n",
    "};\n",
    "\n",
    "// Define a semantic configuration\n",
    "var semanticConfig = new SemanticConfiguration(\n",
    "    name: \"semantic_config\",\n",
    "    prioritizedFields: new SemanticPrioritizedFields\n",
    "    {\n",
    "        ContentFields = { new SemanticField(\"page_chunk\") }\n",
    "    }\n",
    ");\n",
    "\n",
    "var semanticSearch = new SemanticSearch()\n",
    "{\n",
    "    DefaultConfigurationName = \"semantic_config\",\n",
    "    Configurations =\n",
    "    {\n",
    "        semanticConfig\n",
    "    }\n",
    "};\n",
    "\n",
    "// Create the index\n",
    "var index = new SearchIndex(indexName)\n",
    "{\n",
    "    Fields = fields,\n",
    "    VectorSearch = vectorSearch,\n",
    "    SemanticSearch = semanticSearch\n",
    "};\n",
    "\n",
    "// Create the index client and create or update the index\n",
    "var indexClient = new SearchIndexClient(new Uri(searchEndpoint), credential);\n",
    "await indexClient.CreateOrUpdateIndexAsync(index);\n",
    "\n",
    "Console.WriteLine($\"Index '{indexName}' created or updated successfully.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d3c782",
   "metadata": {},
   "source": [
    "## Upload sample documents\n",
    "\n",
    "This notebook uses data from NASA's Earth at Night e-book. The data is retrieved from the [azure-search-sample-data](https://github.com/Azure-Samples/azure-search-sample-data) repository on GitHub and passed to the search client for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99f40ac7",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents uploaded to index 'earth-at-night' successfully.\r\n"
     ]
    }
   ],
   "source": [
    "using System.Net.Http;\n",
    "using System.Text.Json;\n",
    "using Azure.Search.Documents;\n",
    "using Azure.Search.Documents.Indexes;\n",
    "using Azure.Search.Documents.Models;\n",
    "\n",
    "// Upload sample documents from the GitHub URL\n",
    "string url = \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/refs/heads/main/nasa-e-book/earth-at-night-json/documents.json\";\n",
    "var httpClient = new HttpClient();\n",
    "var response = await httpClient.GetAsync(url);\n",
    "response.EnsureSuccessStatusCode();\n",
    "var json = await response.Content.ReadAsStringAsync();\n",
    "\n",
    "var documents = JsonSerializer.Deserialize<List<Dictionary<string, object>>>(json);\n",
    "var searchClient = new SearchClient(new Uri(searchEndpoint), indexName, credential);\n",
    "var searchIndexingBufferedSender = new SearchIndexingBufferedSender<Dictionary<string, object>>(\n",
    "    searchClient,\n",
    "    new SearchIndexingBufferedSenderOptions<Dictionary<string, object>>\n",
    "    {\n",
    "        KeyFieldAccessor = doc => doc[\"id\"].ToString(),\n",
    "    }\n",
    ");\n",
    "\n",
    "await searchIndexingBufferedSender.UploadDocumentsAsync(documents);\n",
    "await searchIndexingBufferedSender.FlushAsync();\n",
    "\n",
    "Console.WriteLine($\"Documents uploaded to index '{indexName}' successfully.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4fc8fa",
   "metadata": {},
   "source": [
    "## Create a knowledge source\n",
    "\n",
    "This step creates a knowledge source that targets the index you previously created. In the next step, you create a knowledge agent that uses the knowledge source to orchestrate agentic retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge source 'earth-knowledge-source' created or updated successfully.\r\n"
     ]
    }
   ],
   "source": [
    "using Azure.Search.Documents.Indexes.Models;\n",
    "\n",
    "// Create the knowledge source\n",
    "var indexKnowledgeSource = new SearchIndexKnowledgeSource(\n",
    "    name: knowledgeSourceName,\n",
    "    searchIndexParameters: new SearchIndexKnowledgeSourceParameters(searchIndexName: indexName)\n",
    "    {\n",
    "        SourceDataSelect = \"id,page_chunk,page_number\"\n",
    "    }\n",
    ");\n",
    "\n",
    "await indexClient.CreateOrUpdateKnowledgeSourceAsync(indexKnowledgeSource);\n",
    "Console.WriteLine($\"Knowledge source '{knowledgeSourceName}' created or updated successfully.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af0233",
   "metadata": {},
   "source": [
    "## Create a knowledge agent\n",
    "\n",
    "\n",
    "This step creates a knowledge agent, which acts as a wrapper for your knowledge source and LLM deployment.\n",
    "\n",
    "`ExtractiveData` is the default modality and returns content from your knowledge sources without generative alteration. However, this quickstart uses the `AnswerSynthesis` modality for LLM-generated answers that cite the retrieved content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afd8d8ed",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge agent 'earth-knowledge-agent' created or updated successfully.\r\n"
     ]
    }
   ],
   "source": [
    "using Azure.Search.Documents.Indexes.Models;\n",
    "\n",
    "var openAiParameters = new AzureOpenAIVectorizerParameters\n",
    "{\n",
    "    ResourceUri = new Uri(aoaiEndpoint),\n",
    "    DeploymentName = aoaiGptDeployment,\n",
    "    ModelName = aoaiGptModel\n",
    "};\n",
    "\n",
    "var agentModel = new KnowledgeAgentAzureOpenAIModel(azureOpenAIParameters: openAiParameters);\n",
    "\n",
    "var outputConfig = new KnowledgeAgentOutputConfiguration\n",
    "{\n",
    "    Modality = KnowledgeAgentOutputConfigurationModality.AnswerSynthesis,\n",
    "    IncludeActivity = true\n",
    "};\n",
    "\n",
    "// Create the knowledge agent\n",
    "var agent = new KnowledgeAgent(\n",
    "    name: knowledgeAgentName,\n",
    "    models: new[] { agentModel },\n",
    "    knowledgeSources: new KnowledgeSourceReference[] { new KnowledgeSourceReference(knowledgeSourceName) { IncludeReferences = true, IncludeReferenceSourceData = true, RerankerThreshold = (float?)2.5 }}\n",
    ")\n",
    "{\n",
    "    OutputConfiguration = outputConfig\n",
    "};\n",
    "await indexClient.CreateOrUpdateKnowledgeAgentAsync(agent);\n",
    "Console.WriteLine($\"Knowledge agent '{knowledgeAgentName}' created or updated successfully.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f157c598",
   "metadata": {},
   "source": [
    "## Set up messages\n",
    "\n",
    "Messages are the input for the retrieval route and contain the conversation history. Each message includes a `role` that indicates its origin, such as `system` or `user`, and `content` in natural language. The LLM you use determines which roles are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed6ff9dc",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "string instructions = @\"\n",
    "A Q&A agent that can answer questions about the Earth at night.\n",
    "If you don't have the answer, respond with \"\"I don't know\"\".\n",
    "\";\n",
    "\n",
    "var messages = new List<Dictionary<string, string>>\n",
    "{\n",
    "    new Dictionary<string, string>\n",
    "    {\n",
    "        { \"role\", \"system\" },\n",
    "        { \"content\", instructions }\n",
    "    }\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb21be04",
   "metadata": {},
   "source": [
    "## Use agentic retrieval to fetch results\n",
    "\n",
    "This step runs the agentic retrieval pipeline to produce a grounded, citation-backed answer. Given the conversation history and retrieval parameters, your knowledge agent:\n",
    "\n",
    "1. Analyzes the entire conversation to infer the user's information need.\n",
    "\n",
    "1. Decomposes the compound query into focused subqueries.\n",
    "\n",
    "1. Runs the subqueries concurrently against your knowledge source.\n",
    "\n",
    "1. Uses semantic ranker to rerank and filter the results.\n",
    "\n",
    "1. Synthesizes the top results into a natural-language answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "239a9e12",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Azure.Search.Documents.Agents;\n",
    "using Azure.Search.Documents.Agents.Models;\n",
    "\n",
    "var agentClient = new KnowledgeAgentRetrievalClient(\n",
    "    endpoint: new Uri(searchEndpoint),\n",
    "    agentName: knowledgeAgentName,\n",
    "    tokenCredential: new DefaultAzureCredential()\n",
    ");\n",
    "\n",
    "messages.Add(new Dictionary<string, string>\n",
    "{\n",
    "    { \"role\", \"user\" },\n",
    "    { \"content\", @\"\n",
    "Why do suburban belts display larger December brightening than urban cores even though absolute light levels are higher downtown?\n",
    "Why is the Phoenix nighttime street grid is so sharply visible from space, whereas large stretches of the interstate between midwestern cities remain comparatively dim?\n",
    "\" }\n",
    "});\n",
    "\n",
    "var retrievalResult = await agentClient.RetrieveAsync(\n",
    "    retrievalRequest: new KnowledgeAgentRetrievalRequest(\n",
    "        messages: messages\n",
    "            .Where(message => message[\"role\"] != \"system\")\n",
    "            .Select(\n",
    "            message => new KnowledgeAgentMessage(content: new[] { new KnowledgeAgentMessageTextContent(message[\"content\"]) })  { Role = message[\"role\"] }\n",
    "            )\n",
    "            .ToList()\n",
    "    )\n",
    ");\n",
    "\n",
    "messages.Add(new Dictionary<string, string>\n",
    "{\n",
    "    { \"role\", \"assistant\" },\n",
    "    { \"content\", (retrievalResult.Value.Response[0].Content[0] as KnowledgeAgentMessageTextContent).Text }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ddaf4f",
   "metadata": {},
   "source": [
    "### Review the retrieval response, activity, and results\n",
    "\n",
    "Because your knowledge agent is configured for answer synthesis, the retrieval response contains the following values:\n",
    "\n",
    "+ `Response`: An LLM-generated answer to the query that cites the retrieved documents.\n",
    "\n",
    "+ `Activity`: Detailed planning and execution information, including subqueries, reranking decisions, and intermediate steps.\n",
    "\n",
    "+ `References`: Source documents and chunks that contributed to the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80676736",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburban belts display larger December brightening than urban cores, despite higher absolute light levels in downtown areas, likely due to the expansive holiday light displays in residential neighborhoods and commercial areas that tend to be more prevalent in suburban settings. This contributes to a greater relative increase in lighting during the holiday season compared to urban cores, which might have higher baseline lighting that does not change as dramatically [ref_id:1][ref_id:3]. \n",
       "\n",
       "Additionally, the Phoenix nighttime street grid is sharply visible from space due to its organized layout and extensive street lighting that outlines the city's grid pattern, making it easier to discern from low-Earth orbit. In contrast, large stretches of the interstate between midwestern cities remain comparatively dim because these highways often traverse less densely populated or rural areas with fewer lighting installations. The more pronounced urban lighting, as seen in cities like Phoenix, contrasts with the dimness of extensive non-urbanized areas, therefore highlighting the difference in visibility from space [ref_id:0][ref_id:4][ref_id:10]."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(retrievalResult.Value.Response[0].Content[0] as KnowledgeAgentMessageTextContent).Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ace2c90",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity:\n",
      "Activity Type: KnowledgeAgentModelQueryPlanningActivityRecord\n",
      "{\n",
      "  \"InputTokens\": 2278,\n",
      "  \"OutputTokens\": 153,\n",
      "  \"Id\": 0,\n",
      "  \"ElapsedMs\": 3420\n",
      "}\n",
      "Activity Type: KnowledgeAgentSearchIndexActivityRecord\n",
      "{\n",
      "  \"SearchIndexArguments\": {\n",
      "    \"Search\": \"Why do suburban belts show larger December brightening than urban cores despite higher absolute light levels downtown?\",\n",
      "    \"Filter\": null\n",
      "  },\n",
      "  \"KnowledgeSourceName\": \"earth-knowledge-source\",\n",
      "  \"QueryTime\": \"2025-09-23T13:44:16.903+00:00\",\n",
      "  \"Count\": 0,\n",
      "  \"Id\": 1,\n",
      "  \"ElapsedMs\": 901\n",
      "}\n",
      "Activity Type: KnowledgeAgentSearchIndexActivityRecord\n",
      "{\n",
      "  \"SearchIndexArguments\": {\n",
      "    \"Search\": \"Why is the Phoenix nighttime street grid sharply visible from space compared to dimmer stretches of interstate between Midwestern cities?\",\n",
      "    \"Filter\": null\n",
      "  },\n",
      "  \"KnowledgeSourceName\": \"earth-knowledge-source\",\n",
      "  \"QueryTime\": \"2025-09-23T13:44:17.33+00:00\",\n",
      "  \"Count\": 0,\n",
      "  \"Id\": 2,\n",
      "  \"ElapsedMs\": 427\n",
      "}\n",
      "Activity Type: KnowledgeAgentSemanticRerankerActivityRecord\n",
      "{\n",
      "  \"InputTokens\": 46634,\n",
      "  \"Id\": 3,\n",
      "  \"ElapsedMs\": null\n",
      "}\n",
      "Activity Type: KnowledgeAgentModelAnswerSynthesisActivityRecord\n",
      "{\n",
      "  \"InputTokens\": 2347,\n",
      "  \"OutputTokens\": 14,\n",
      "  \"Id\": 4,\n",
      "  \"ElapsedMs\": 457\n",
      "}\n",
      "Results\n"
     ]
    }
   ],
   "source": [
    "Console.WriteLine(\"Activity:\");\n",
    "foreach (var activity in retrievalResult.Value.Activity)\n",
    "{\n",
    "    Console.WriteLine($\"Activity Type: {activity.GetType().Name}\");\n",
    "    string json = JsonSerializer.Serialize(\n",
    "        activity,\n",
    "        activity.GetType(),\n",
    "        new JsonSerializerOptions { WriteIndented = true }\n",
    "    );\n",
    "    Console.WriteLine(json);\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"Results\");\n",
    "foreach (var reference in retrievalResult.Value.References)\n",
    "{\n",
    "    Console.WriteLine($\"Reference Type: {reference.GetType().Name}\");\n",
    "    string json = JsonSerializer.Serialize(\n",
    "        reference,\n",
    "        reference.GetType(),\n",
    "        new JsonSerializerOptions { WriteIndented = true }\n",
    "    );\n",
    "    Console.WriteLine(json);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27116bc",
   "metadata": {},
   "source": [
    "## Continue the conversation\n",
    "\n",
    "This step continues the conversation with your knowledge agent, building upon the previous messages and queries to retrieve relevant information from your knowledge source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e241e04a",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "messages.Add(new Dictionary<string, string>\n",
    "{\n",
    "    { \"role\", \"user\" },\n",
    "    { \"content\", \"How do I find lava at night?\" }\n",
    "});\n",
    "\n",
    "\n",
    "var retrievalResult = await agentClient.RetrieveAsync(\n",
    "    retrievalRequest: new KnowledgeAgentRetrievalRequest(\n",
    "            messages: messages\n",
    "                .Where(message => message[\"role\"] != \"system\")\n",
    "                .Select(\n",
    "                    message => new KnowledgeAgentMessage(content: new[] { new KnowledgeAgentMessageTextContent(message[\"content\"]) })  { Role = message[\"role\"] }\n",
    "                )\n",
    "                .ToList()\n",
    "            )\n",
    "    );\n",
    "\n",
    "messages.Add(new Dictionary<string, string>\n",
    "{\n",
    "    { \"role\", \"assistant\" },\n",
    "    { \"content\", (retrievalResult.Value.Response[0].Content[0] as KnowledgeAgentMessageTextContent).Text }\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96373661",
   "metadata": {},
   "source": [
    "### Review the new retrieval response, activity, and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9927d10",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lava can be found at night by using satellite imagery that captures thermal and infrared wavelengths, which highlight the hot lava as bright white or red areas against the cooler surroundings. For example, Landsat 8 imagery combines thermal, shortwave infrared, and near-infrared wavelengths to detect very hot lava flows, cooling lava, and areas obscured by clouds, as seen in the monitoring of Kilauea's lava flows in Hawaii [ref_id:0]. Similarly, the Operational Land Imager (OLI) and Thermal Infrared Sensor (TIRS) on Landsat 8 can highlight active vents and lava flows, as demonstrated during Mount Etna's flank eruption in Italy [ref_id:1]. Additionally, the VIIRS Day/Night Band (DNB) on the Suomi NPP satellite can capture nighttime images of glowing lava flows, using faint light sources such as moonlight to illuminate the scene, enabling the detection of lava activity at night, as shown in images of Mount Etna [ref_id:2][ref_id:5]. Thus, by utilizing satellite instruments that detect thermal infrared and near-infrared light, combined with nightlight data illuminated by moonlight or other faint sources, lava flows can be effectively found and monitored at night."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(retrievalResult.Value.Response[0].Content[0] as KnowledgeAgentMessageTextContent).Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "462137b4",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity:\n",
      "Activity Type: KnowledgeAgentModelQueryPlanningActivityRecord\n",
      "{\n",
      "  \"InputTokens\": 2311,\n",
      "  \"OutputTokens\": 81,\n",
      "  \"Id\": 0,\n",
      "  \"ElapsedMs\": 3944\n",
      "}\n",
      "Activity Type: KnowledgeAgentSearchIndexActivityRecord\n",
      "{\n",
      "  \"SearchIndexArguments\": {\n",
      "    \"Search\": \"How to locate lava flows at night\",\n",
      "    \"Filter\": null\n",
      "  },\n",
      "  \"KnowledgeSourceName\": \"earth-knowledge-source\",\n",
      "  \"QueryTime\": \"2025-09-23T13:44:34.427+00:00\",\n",
      "  \"Count\": 6,\n",
      "  \"Id\": 1,\n",
      "  \"ElapsedMs\": 405\n",
      "}\n",
      "Activity Type: KnowledgeAgentSearchIndexActivityRecord\n",
      "{\n",
      "  \"SearchIndexArguments\": {\n",
      "    \"Search\": \"Methods for detecting lava at night\",\n",
      "    \"Filter\": null\n",
      "  },\n",
      "  \"KnowledgeSourceName\": \"earth-knowledge-source\",\n",
      "  \"QueryTime\": \"2025-09-23T13:44:34.797+00:00\",\n",
      "  \"Count\": 2,\n",
      "  \"Id\": 2,\n",
      "  \"ElapsedMs\": 369\n",
      "}\n",
      "Activity Type: KnowledgeAgentSearchIndexActivityRecord\n",
      "{\n",
      "  \"SearchIndexArguments\": {\n",
      "    \"Search\": \"Safety tips for finding lava at night\",\n",
      "    \"Filter\": null\n",
      "  },\n",
      "  \"KnowledgeSourceName\": \"earth-knowledge-source\",\n",
      "  \"QueryTime\": \"2025-09-23T13:44:35.355+00:00\",\n",
      "  \"Count\": 0,\n",
      "  \"Id\": 3,\n",
      "  \"ElapsedMs\": 558\n",
      "}\n",
      "Activity Type: KnowledgeAgentSemanticRerankerActivityRecord\n",
      "{\n",
      "  \"InputTokens\": 67218,\n",
      "  \"Id\": 4,\n",
      "  \"ElapsedMs\": null\n",
      "}\n",
      "Activity Type: KnowledgeAgentModelAnswerSynthesisActivityRecord\n",
      "{\n",
      "  \"InputTokens\": 5355,\n",
      "  \"OutputTokens\": 260,\n",
      "  \"Id\": 5,\n",
      "  \"ElapsedMs\": 5539\n",
      "}\n",
      "Results\n",
      "Reference Type: KnowledgeAgentSearchIndexReference\n",
      "{\n",
      "  \"DocKey\": \"earth_at_night_508_page_60_verbalized\",\n",
      "  \"Id\": \"0\",\n",
      "  \"ActivitySource\": 1,\n",
      "  \"SourceData\": {\n",
      "    \"id\": \"earth_at_night_508_page_60_verbalized\",\n",
      "    \"page_chunk\": \"\\u003C!-- PageHeader=\\u0022Volcanoes\\u0022 --\\u003E\\n\\n## Volcanoes\\n\\n### The Infrared Glows of Kilauea\\u0027s Lava Flows\\u2014Hawaii\\n\\nIn early May 2018, an eruption on Hawaii\\u0027s Kilauea volcano began to unfold. The eruption took a dangerous turn on May 3, 2018, when new fissures opened in the residential neighborhood of Leilani Estates. During the summer-long eruptive event, other fissures emerged along the East Rift Zone. Lava from vents along the rift zone flowed downslope, reaching the ocean in several areas, and filling in Kapoho Bay.\\n\\nA time series of Landsat 8 imagery shows the progression of the lava flows from May 16 to August 13. The night view combines thermal, shortwave infrared, and near-infrared wavelengths to tease out the very hot lava (bright white), cooling lava (red), and lava flows obstructed by clouds (purple).\\n\\n#### Figure: Location of Kilauea Volcano, Hawaii\\n\\nA globe is shown centered on North America, with a marker placed in the Pacific Ocean indicating the location of Hawaii, to the southwest of the mainland United States.\\n\\n\\u003C!-- PageFooter=\\u0022Earth at Night\\u0022 --\\u003E\\n\\u003C!-- PageNumber=\\u002244\\u0022 --\\u003E\",\n",
      "    \"page_number\": 60\n",
      "  },\n",
      "  \"RerankerScore\": 2.779123\n",
      "}\n",
      "Reference Type: KnowledgeAgentSearchIndexReference\n",
      "{\n",
      "  \"DocKey\": \"earth_at_night_508_page_64_verbalized\",\n",
      "  \"Id\": \"2\",\n",
      "  \"ActivitySource\": 1,\n",
      "  \"SourceData\": {\n",
      "    \"id\": \"earth_at_night_508_page_64_verbalized\",\n",
      "    \"page_chunk\": \"\\u003C!-- PageHeader=\\u0022Volcanoes\\u0022 --\\u003E\\n\\n### Nighttime Glow at Mount Etna - Italy\\n\\nAt about 2:30 a.m. local time on March 16, 2017, the VIIRS DNB on the Suomi NPP satellite captured this nighttime image of lava flowing on Mount Etna in Sicily, Italy. Etna is one of the world\\u0027s most active volcanoes.\\n\\n#### Figure: Location of Mount Etna\\nA world globe is depicted, with a marker indicating the location of Mount Etna in Sicily, Italy, in southern Europe near the center of the Mediterranean Sea.\\n\\n\\u003C!-- PageFooter=\\u0022Earth at Night\\u0022 --\\u003E\\n\\u003C!-- PageNumber=\\u002248\\u0022 --\\u003E\",\n",
      "    \"page_number\": 64\n",
      "  },\n",
      "  \"RerankerScore\": 2.7684891\n",
      "}\n",
      "Reference Type: KnowledgeAgentSearchIndexReference\n",
      "{\n",
      "  \"DocKey\": \"earth_at_night_508_page_46_verbalized\",\n",
      "  \"Id\": \"1\",\n",
      "  \"ActivitySource\": 2,\n",
      "  \"SourceData\": {\n",
      "    \"id\": \"earth_at_night_508_page_46_verbalized\",\n",
      "    \"page_chunk\": \"For the first time in perhaps a decade, Mount Etna experienced a \\u0022flank eruption\\u0022\\u2014erupting from its side instead of its summit\\u2014on December 24, 2018. The activity was accompanied by 130 earthquakes occurring over three hours that morning. Mount Etna, Europe\\u2019s most active volcano, has seen periodic activity on this part of the mountain since 2013. The Operational Land Imager (OLI) on the Landsat 8 satellite acquired the main image of Mount Etna on December 28, 2018.\\n\\nThe inset image highlights the active vent and thermal infrared signature from lava flows, which can be seen near the newly formed fissure on the southeastern side of the volcano. The inset was created with data from OLI and the Thermal Infrared Sensor (TIRS) on Landsat 8. Ash spewing from the fissure cloaked adjacent villages and delayed aircraft from landing at the nearby Catania airport. Earthquakes occurred in the subsequent days after the initial eruption and displaced hundreds of people from their homes.\\n\\nFor nighttime images of Mount Etna\\u2019s March 2017 eruption, see pages 48\\u201351.\\n\\n---\\n\\n### Hazards of Volcanic Ash Plumes and Satellite Observation\\n\\nWith the help of moonlight, satellite instruments can track volcanic ash plumes, which present significant hazards to airplanes in flight. The volcanic ash\\u2014composed of tiny pieces of glass and rock\\u2014is abrasive to engine turbine blades, and can melt on the blades and other engine parts, causing damage and even engine stalls. This poses a danger to both the plane\\u2019s integrity and passenger safety. Volcanic ash also reduces visibility for pilots and can cause etching of windshields, further reducing pilots\\u2019 ability to see. Nightlight images can be combined with thermal images to provide a more complete view of volcanic activity on Earth\\u2019s surface.\\n\\nThe VIIRS Day/Night Band (DNB) on polar-orbiting satellites uses faint light sources such as moonlight, airglow (the atmosphere\\u2019s self-illumination through chemical reactions), zodiacal light (sunlight scattered by interplanetary dust), and starlight from the Milky Way. Using these dim light sources, the DNB can detect changes in clouds, snow cover, and sea ice:\\n\\n#### Table: Light Sources Used by VIIRS DNB\\n\\n| Light Source         | Description                                                                  |\\n|----------------------|------------------------------------------------------------------------------|\\n| Moonlight            | Reflected sunlight from the Moon, illuminating Earth\\u0027s surface at night      |\\n| Airglow              | Atmospheric self-illumination from chemical reactions                        |\\n| Zodiacal Light       | Sunlight scattered by interplanetary dust                                    |\\n| Starlight/Milky Way  | Faint illumination provided by stars in the Milky Way                        |\\n\\nGeostationary Operational Environmental Satellites (GOES), managed by NOAA, orbit over Earth\\u2019s equator and offer uninterrupted observations of North America. High-latitude areas such as Alaska benefit from polar-orbiting satellites like Suomi NPP, which provide overlapping coverage at the poles, enabling more data collection in these regions. During polar darkness (winter months), VIIRS DNB data allow scientists to:\\n\\n- Observe sea ice formation\\n- Monitor snow cover extent at the highest latitudes\\n- Detect open water for ship navigation\\n\\n#### Table: Satellite Coverage Overview\\n\\n| Satellite Type          | Orbit           | Coverage Area         | Special Utility                              |\\n|------------------------|-----------------|----------------------|----------------------------------------------|\\n| GOES                   | Geostationary   | Equatorial/North America | Continuous regional monitoring              |\\n| Polar-Orbiting (e.g., Suomi NPP) | Polar-orbiting    | Poles/high latitudes      | Overlapping passes; useful during polar night|\\n\\n---\\n\\n### Weather Forecasting and Nightlight Data\\n\\nThe use of nightlight data by weather forecasters is growing as the VIIRS instrument enables observation of clouds at night illuminated by sources such as moonlight and lightning. Scientists use these data to study the nighttime behavior of weather systems, including severe storms, which can develop and strike populous areas at night as well as during the day. Combined with thermal data, visible nightlight data allow the detection of clouds at various heights in the atmosphere, such as dense marine fog. This capability enables weather forecasters to issue marine advisories with higher confidence, leading to greater utility. (See \\u0022Marine Layer Clouds\\u2014California\\u0022 on page 56.)\\n\\nIn this section of the book, you will see how nightlight data are used to observe nature\\u2019s spectacular light shows across a wide range of sources.\\n\\n---\\n\\n#### Notable Data from Mount Etna Flank Eruption (December 2018)\\n\\n| Event/Observation                  | Details                                                                    |\\n|-------------------------------------|----------------------------------------------------------------------------|\\n| Date of Flank Eruption              | December 24, 2018                                                          |\\n| Number of Earthquakes               | 130 earthquakes within 3 hours                                              |\\n| Image Acquisition                   | December 28, 2018 by Landsat 8 OLI                                         |\\n| Location of Eruption                | Southeastern side of Mount Etna                                            |\\n| Thermal Imaging Data                | From OLI and TIRS (Landsat 8), highlighting active vent and lava flows     |\\n| Impact on Villages/Air Transport    | Ash covered villages; delayed aircraft at Catania airport                  |\\n| Displacement                        | Hundreds of residents displaced                                            |\\n| Ongoing Seismic Activity            | Earthquakes continued after initial eruption                               |\\n\\n---\\n\\n\\u003C!-- PageFooter=\\u0022Earth at Night\\u0022 --\\u003E\\n\\u003C!-- PageNumber=\\u002230\\u0022 --\\u003E\",\n",
      "    \"page_number\": 46\n",
      "  },\n",
      "  \"RerankerScore\": 2.6940506\n",
      "}\n",
      "Reference Type: KnowledgeAgentSearchIndexReference\n",
      "{\n",
      "  \"DocKey\": \"earth_at_night_508_page_66_verbalized\",\n",
      "  \"Id\": \"4\",\n",
      "  \"ActivitySource\": 1,\n",
      "  \"SourceData\": {\n",
      "    \"id\": \"earth_at_night_508_page_66_verbalized\",\n",
      "    \"page_chunk\": \"# Volcanoes\\n\\n---\\n\\n### Mount Etna Erupts - Italy\\n\\nThe highly active Mount Etna in Italy sent red lava rolling down its flank on March 19, 2017. An astronaut onboard the ISS took the photograph below of the volcano and its environs that night. City lights surround the mostly dark volcanic area.\\n\\n---\\n\\n#### Figure 1: Location of Mount Etna, Italy\\n\\nA world map highlighting the location of Mount Etna in southern Italy. The marker indicates its geographic placement on the east coast of Sicily, Italy, in the Mediterranean region, south of mainland Europe and north of northern Africa.\\n\\n---\\n\\n#### Figure 2: Nighttime View of Mount Etna\\u0027s Eruption and Surrounding Cities\\n\\nThis is a nighttime satellite image taken on March 19, 2017, showing the eruption of Mount Etna (southeastern cone) with visible bright red and orange coloring indicating flowing lava from a lateral vent. The surrounding areas are illuminated by city lights, with the following geographic references labeled:\\n\\n| Location        | Position in Image         | Visible Characteristics                    |\\n|-----------------|--------------------------|--------------------------------------------|\\n| Mt. Etna (southeastern cone) | Top center-left | Bright red/orange lava flow                |\\n| Lateral vent    | Left of the volcano       | Faint red/orange flow extending outwards   |\\n| Resort          | Below the volcano, to the left   | Small cluster of lights                    |\\n| Giarre          | Top right                 | Bright cluster of city lights              |\\n| Acireale        | Center right              | Large, bright area of city lights          |\\n| Biancavilla     | Bottom left               | Smaller cluster of city lights             |\\n\\nAn arrow pointing north is shown on the image for orientation.\\n\\n---\\n\\n\\u003C!-- Earth at Night Page Footer --\\u003E\\n\\u003C!-- Page Number: 50 --\\u003E\",\n",
      "    \"page_number\": 66\n",
      "  },\n",
      "  \"RerankerScore\": 2.6189032\n",
      "}\n",
      "Reference Type: KnowledgeAgentSearchIndexReference\n",
      "{\n",
      "  \"DocKey\": \"earth_at_night_508_page_44_verbalized\",\n",
      "  \"Id\": \"3\",\n",
      "  \"ActivitySource\": 2,\n",
      "  \"SourceData\": {\n",
      "    \"id\": \"earth_at_night_508_page_44_verbalized\",\n",
      "    \"page_chunk\": \"## Nature\\u0027s Light Shows\\n\\nAt night, with the light of the Sun removed, nature\\u0027s brilliant glow from Earth\\u0027s surface becomes visible to the naked eye from space. Some of Earth\\u0027s most spectacular light shows are natural, like the aurora borealis, or Northern Lights, in the Northern Hemisphere (aurora australis, or Southern Lights, in the Southern Hemisphere). The auroras are natural electrical phenomena caused by charged particles that race from the Sun toward Earth, inducing chemical reactions in the upper atmosphere and creating the appearance of streamers of reddish or greenish light in the sky, usually near the northern or southern magnetic pole. Other natural lights can indicate danger, like a raging forest fire encroaching on a city, town, or community, or lava spewing from an erupting volcano.\\n\\nWhatever the source, the ability of humans to monitor nature\\u0027s light shows at night has practical applications for society. For example, tracking fires during nighttime hours allows for continuous monitoring and enhances our ability to protect humans and other animals, plants, and infrastructure. Combined with other data sources, our ability to observe the light of fires at night allows emergency managers to more efficiently and accurately issue warnings and evacuation orders and allows firefighting efforts to continue through the night. With enough moonlight (e.g., full-Moon phase), it\\u0027s even possible to track the movement of smoke plumes at night, which can impact air quality, regardless of time of day.\\n\\nAnother natural source of light at night is emitted from glowing lava flows at the site of active volcanoes. Again, with enough moonlight, these dramatic scenes can be tracked and monitored for both scientific research and public safety.\\n\\n\\n### Figure: The Northern Lights Viewed from Space\\n\\n**September 17, 2011**\\n\\nThis photo, taken from the International Space Station on September 17, 2011, shows a spectacular display of the aurora borealis (Northern Lights) as green and reddish light in the night sky above Earth. In the foreground, part of a Soyuz spacecraft is visible, silhouetted against the bright auroral light. The green glow is generated by energetic charged particles from the Sun interacting with Earth\\u0027s upper atmosphere, exciting oxygen and nitrogen atoms, and producing characteristic colors. The image demonstrates the vividness and grandeur of natural night-time light phenomena as seen from orbit.\",\n",
      "    \"page_number\": 44\n",
      "  },\n",
      "  \"RerankerScore\": 2.5664418\n",
      "}\n",
      "Reference Type: KnowledgeAgentSearchIndexReference\n",
      "{\n",
      "  \"DocKey\": \"earth_at_night_508_page_65_verbalized\",\n",
      "  \"Id\": \"5\",\n",
      "  \"ActivitySource\": 1,\n",
      "  \"SourceData\": {\n",
      "    \"id\": \"earth_at_night_508_page_65_verbalized\",\n",
      "    \"page_chunk\": \"# Volcanoes\\n\\n## Figure: Satellite Image of Sicily and Mount Etna Lava, March 16, 2017\\n\\nThe annotated satellite image below shows the island of Sicily and the surrounding region at night, highlighting city lights and volcanic activity.\\n\\n**Description:**\\n\\n- **Date of image:** March 16, 2017\\n- **Geographical locations labeled:**\\n    - Major cities: Palermo (northwest Sicily), Marsala (western Sicily), Catania (eastern Sicily)\\n    - Significant feature: Mount Etna, labeled with an adjacent \\u0022hot lava\\u0022 region showing the glow from active lava flows\\n    - Surrounding water body: Mediterranean Sea\\n    - Island: Malta to the south of Sicily\\n- **Other details:** \\n    - The image is shown at night, with bright spots indicating city lights.\\n    - The position of \\u0022hot lava\\u0022 near Mount Etna is distinctly visible as a bright spot different from other city lights, indicating volcanic activity.\\n    - A scale bar is included showing a reference length of 50 km.\\n    - North direction is indicated with an arrow.\\n    - Cloud cover is visible in the southwest part of the image, partially obscuring the view near Marsala and Malta.\\n\\n**Summary of Features Visualized:**\\n\\n| Feature          | Description                                           |\\n|------------------|------------------------------------------------------|\\n| Cities           | Bright clusters indicating locations: Palermo, Marsala, Catania |\\n| Mount Etna       | Marked on the map, located on the eastern side of Sicily, with visible hot lava activity |\\n| Malta            | Clearly visible to the south of Sicily               |\\n| Water bodies     | Mediterranean Sea labeled                            |\\n| Scale \\u0026 Direction| 50 km scale bar and North indicator                  |\\n| Date             | March 16, 2017                                       |\\n| Cloud Cover      | Visible in the lower left (southern) part of the image |\\n\\nThis figure demonstrates the visibility of volcanic activity at Mount Etna from space at night, distinguishing the light from hot lava against the background city lights of Sicily and Malta.\",\n",
      "    \"page_number\": 65\n",
      "  },\n",
      "  \"RerankerScore\": 2.5382614\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "Console.WriteLine(\"Activity:\");\n",
    "foreach (var activity in retrievalResult.Value.Activity)\n",
    "{\n",
    "    Console.WriteLine($\"Activity Type: {activity.GetType().Name}\");\n",
    "    string json = JsonSerializer.Serialize(\n",
    "        activity,\n",
    "        activity.GetType(),\n",
    "        new JsonSerializerOptions { WriteIndented = true }\n",
    "    );\n",
    "    Console.WriteLine(json);\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"Results\");\n",
    "foreach (var reference in retrievalResult.Value.References)\n",
    "{\n",
    "    Console.WriteLine($\"Reference Type: {reference.GetType().Name}\");\n",
    "    string json = JsonSerializer.Serialize(\n",
    "        reference,\n",
    "        reference.GetType(),\n",
    "        new JsonSerializerOptions { WriteIndented = true }\n",
    "    );\n",
    "    Console.WriteLine(json);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80883384",
   "metadata": {},
   "source": [
    "## Clean up objects and resources\n",
    "\n",
    "If you no longer need Azure AI Search or Azure AI Foundry, delete the resources from your Azure subscription. You can also start over by deleting individual objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3532f3",
   "metadata": {},
   "source": [
    "### Delete the knowledge agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c7bb888",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge agent 'earth-knowledge-agent' deleted successfully.\r\n"
     ]
    }
   ],
   "source": [
    "await indexClient.DeleteKnowledgeAgentAsync(knowledgeAgentName);\n",
    "System.Console.WriteLine($\"Knowledge agent '{knowledgeAgentName}' deleted successfully.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6354bf2",
   "metadata": {},
   "source": [
    "### Delete the knowledge source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge source 'earth-knowledge-source' deleted successfully.\r\n"
     ]
    }
   ],
   "source": [
    "await indexClient.DeleteKnowledgeSourceAsync(knowledgeSourceName);\n",
    "System.Console.WriteLine($\"Knowledge source '{knowledgeSourceName}' deleted successfully.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e88e9c",
   "metadata": {},
   "source": [
    "### Delete the search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5c709f0",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'earth-at-night' deleted successfully.\r\n"
     ]
    }
   ],
   "source": [
    "await indexClient.DeleteIndexAsync(indexName);\n",
    "System.Console.WriteLine($\"Index '{indexName}' deleted successfully.\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
